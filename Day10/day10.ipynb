{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7613707c",
   "metadata": {},
   "source": [
    "## Coding: \n",
    "Use DSPy (or a simplified version if DSPy isn’t accessible) to optimize a multi-step QA pipeline. For example, pipeline: (1) retrieve relevant text from a small corpus, (2) ask LLM to answer question given retrieved text. Define the metric as accuracy of answer. Let the system tune the retrieval prompt and answer prompt. Observe what changes it makes (e.g. does it add “Let’s think step by step” automatically?). Report the before vs after performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2d61ab87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid -W option ignored: invalid module name: 'urllib3.exceptions'\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: dspy in /Users/namitha/Library/Python/3.9/lib/python/site-packages (2.6.27)\n",
      "Requirement already satisfied: wikipedia in /Users/namitha/Library/Python/3.9/lib/python/site-packages (1.4.0)\n",
      "Requirement already satisfied: python-dotenv in /Users/namitha/Library/Python/3.9/lib/python/site-packages (1.2.1)\n",
      "Requirement already satisfied: backoff>=2.2 in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from dspy) (2.2.1)\n",
      "Requirement already satisfied: joblib~=1.3 in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from dspy) (1.5.3)\n",
      "Requirement already satisfied: openai>=0.28.1 in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from dspy) (2.15.0)\n",
      "Requirement already satisfied: pandas>=2.1.1 in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from dspy) (2.3.3)\n",
      "Requirement already satisfied: regex>=2023.10.3 in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from dspy) (2025.11.3)\n",
      "Requirement already satisfied: ujson>=5.8.0 in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from dspy) (5.11.0)\n",
      "Requirement already satisfied: tqdm>=4.66.1 in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from dspy) (4.67.1)\n",
      "Requirement already satisfied: datasets>=2.14.6 in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from dspy) (4.4.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from dspy) (2.32.5)\n",
      "Requirement already satisfied: optuna>=3.4.0 in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from dspy) (4.6.0)\n",
      "Requirement already satisfied: pydantic>=2.0 in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from dspy) (2.12.5)\n",
      "Requirement already satisfied: magicattr>=0.1.6 in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from dspy) (0.1.6)\n",
      "Requirement already satisfied: litellm>=1.60.3 in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from dspy) (1.80.16)\n",
      "Requirement already satisfied: diskcache>=5.6.0 in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from dspy) (5.6.3)\n",
      "Requirement already satisfied: json-repair>=0.30.0 in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from dspy) (0.44.1)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from dspy) (9.1.2)\n",
      "Requirement already satisfied: anyio in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from dspy) (4.12.1)\n",
      "Requirement already satisfied: asyncer==0.0.8 in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from dspy) (0.0.8)\n",
      "Requirement already satisfied: cachetools>=5.5.0 in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from dspy) (6.2.4)\n",
      "Requirement already satisfied: cloudpickle>=3.0.0 in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from dspy) (3.1.2)\n",
      "Requirement already satisfied: rich>=13.7.1 in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from dspy) (14.2.0)\n",
      "Requirement already satisfied: numpy<2.2,>=1.26.0 in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from dspy) (2.0.2)\n",
      "Requirement already satisfied: typing_extensions>=4.8.0 in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from asyncer==0.0.8->dspy) (4.15.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from anyio->dspy) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from anyio->dspy) (3.11)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from wikipedia) (4.14.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from requests>=2.31.0->dspy) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from requests>=2.31.0->dspy) (2.6.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from requests>=2.31.0->dspy) (2026.1.4)\n",
      "Requirement already satisfied: filelock in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from datasets>=2.14.6->dspy) (3.19.1)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from datasets>=2.14.6->dspy) (21.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from datasets>=2.14.6->dspy) (0.4.0)\n",
      "Requirement already satisfied: httpx<1.0.0 in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from datasets>=2.14.6->dspy) (0.28.1)\n",
      "Requirement already satisfied: xxhash in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from datasets>=2.14.6->dspy) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from datasets>=2.14.6->dspy) (0.70.18)\n",
      "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.14.6->dspy) (2025.10.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from datasets>=2.14.6->dspy) (0.36.0)\n",
      "Requirement already satisfied: packaging in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from datasets>=2.14.6->dspy) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from datasets>=2.14.6->dspy) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.14.6->dspy) (3.13.3)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from httpx<1.0.0->datasets>=2.14.6->dspy) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from httpcore==1.*->httpx<1.0.0->datasets>=2.14.6->dspy) (0.16.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets>=2.14.6->dspy) (1.2.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.14.6->dspy) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.14.6->dspy) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.14.6->dspy) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.14.6->dspy) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.14.6->dspy) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.14.6->dspy) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.14.6->dspy) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.14.6->dspy) (1.22.0)\n",
      "Requirement already satisfied: click in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from litellm>=1.60.3->dspy) (8.1.8)\n",
      "Requirement already satisfied: fastuuid>=0.13.0 in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from litellm>=1.60.3->dspy) (0.14.0)\n",
      "Requirement already satisfied: grpcio!=1.68.*,!=1.69.*,!=1.70.*,!=1.71.0,!=1.71.1,!=1.72.0,!=1.72.1,!=1.73.0,>=1.62.3 in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from litellm>=1.60.3->dspy) (1.76.0)\n",
      "Requirement already satisfied: importlib-metadata>=6.8.0 in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from litellm>=1.60.3->dspy) (8.7.1)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from litellm>=1.60.3->dspy) (3.1.6)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.23.0 in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from litellm>=1.60.3->dspy) (4.25.1)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from litellm>=1.60.3->dspy) (0.12.0)\n",
      "Requirement already satisfied: tokenizers in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from litellm>=1.60.3->dspy) (0.22.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from jinja2<4.0.0,>=3.1.2->litellm>=1.60.3->dspy) (3.0.3)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from jsonschema<5.0.0,>=4.23.0->litellm>=1.60.3->dspy) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from jsonschema<5.0.0,>=4.23.0->litellm>=1.60.3->dspy) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from jsonschema<5.0.0,>=4.23.0->litellm>=1.60.3->dspy) (0.27.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from pydantic>=2.0->dspy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from pydantic>=2.0->dspy) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from pydantic>=2.0->dspy) (0.4.2)\n",
      "Requirement already satisfied: zipp>=3.20 in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from importlib-metadata>=6.8.0->litellm>=1.60.3->dspy) (3.23.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from openai>=0.28.1->dspy) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from openai>=0.28.1->dspy) (0.12.0)\n",
      "Requirement already satisfied: sniffio in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from openai>=0.28.1->dspy) (1.3.1)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from optuna>=3.4.0->dspy) (1.16.5)\n",
      "Requirement already satisfied: colorlog in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from optuna>=3.4.0->dspy) (6.10.1)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from optuna>=3.4.0->dspy) (2.0.45)\n",
      "Requirement already satisfied: Mako in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from alembic>=1.5.0->optuna>=3.4.0->dspy) (1.3.10)\n",
      "Requirement already satisfied: tomli in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from alembic>=1.5.0->optuna>=3.4.0->dspy) (2.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from pandas>=2.1.1->dspy) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from pandas>=2.1.1->dspy) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from pandas>=2.1.1->dspy) (2025.3)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas>=2.1.1->dspy) (1.15.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from rich>=13.7.1->dspy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from rich>=13.7.1->dspy) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from markdown-it-py>=2.2.0->rich>=13.7.1->dspy) (0.1.2)\n",
      "Requirement already satisfied: soupsieve>=1.6.1 in /Users/namitha/Library/Python/3.9/lib/python/site-packages (from beautifulsoup4->wikipedia) (2.8.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install dspy wikipedia python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc3fdabb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warnings suppressed.\n"
     ]
    }
   ],
   "source": [
    "# Suppress warnings\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# Suppress urllib3 warnings\n",
    "os.environ['PYTHONWARNINGS'] = 'ignore::urllib3.exceptions.NotOpenSSLWarning'\n",
    "\n",
    "# Suppress all UserWarnings (including Pydantic)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore', message='.*urllib3.*')\n",
    "warnings.filterwarnings('ignore', message='.*Pydantic.*')\n",
    "warnings.filterwarnings('ignore', message='.*NotOpenSSLWarning.*')\n",
    "\n",
    "print(\"Warnings suppressed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c11bbabb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ DSPy configured with Groq (llama-3.3-70b-versatile)\n"
     ]
    }
   ],
   "source": [
    "import dspy\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 1. Load the variables from .env into the environment\n",
    "load_dotenv()\n",
    "\n",
    "# Configure Groq API key \n",
    "GROQ_API_KEY = os.getenv(\"groq_token\")\n",
    "# Format: 'groq/model-name'\n",
    "try:\n",
    "    lm = dspy.LM(model='groq/llama-3.3-70b-versatile')\n",
    "    dspy.configure(lm=lm)\n",
    "    print(\"✓ DSPy configured with Groq (llama-3.3-70b-versatile)\")\n",
    "except Exception as e:\n",
    "    print(f\"Error configuring Groq: {e}\")\n",
    "    print(\"Trying alternative model...\")\n",
    "    # Fallback to a different Groq model\n",
    "    lm = dspy.LM(model='groq/llama-3.1-70b-versatile')\n",
    "    dspy.configure(lm=lm)\n",
    "    print(\"✓ DSPy configured with Groq (llama-3.1-70b-versatile)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a07740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling RAG program with BootstrapFewShot...\n",
      "This may take a minute...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 1316.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 3 examples for up to 1 rounds, amounting to 4 attempts.\n",
      "✓ Compilation complete!\n",
      "\n",
      "\n",
      "============================================================\n",
      "Question: Who won the Nobel Prize in Literature in 2006 and what is their country?\n",
      "============================================================\n",
      "\n",
      "[Baseline - Unoptimized]\n",
      "Answer: The winner of the Nobel Prize in Literature in 2006 was Orhan Pamuk from Turkey.\n",
      "Context snippets: 5\n",
      "\n",
      "[Optimized - Compiled with BootstrapFewShot]\n",
      "Answer: Orhan Pamuk, Turkey\n",
      "Context snippets: 5\n",
      "\n",
      "============================================================\n",
      "Question: What is the capital of France?\n",
      "============================================================\n",
      "\n",
      "[Baseline - Unoptimized]\n",
      "Answer: Paris\n",
      "Context snippets: 5\n",
      "\n",
      "[Optimized - Compiled with BootstrapFewShot]\n",
      "Answer: Paris\n",
      "Context snippets: 5\n",
      "\n",
      "============================================================\n",
      "Question: Who invented the telephone?\n",
      "============================================================\n",
      "\n",
      "[Baseline - Unoptimized]\n",
      "Answer: Alexander Graham Bell\n",
      "Context snippets: 6\n",
      "\n",
      "[Optimized - Compiled with BootstrapFewShot]\n",
      "Answer: Alexander Graham Bell\n",
      "Context snippets: 6\n",
      "\n",
      "============================================================\n",
      "OPTIMIZED PROMPT LOG (Full History)\n",
      "============================================================\n",
      "\n",
      "Showing last prompt interaction:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2026-01-19T14:07:50.703354]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `context` (str): Wikipedia snippets\n",
      "2. `question` (str):\n",
      "Your output fields are:\n",
      "1. `reasoning` (str): \n",
      "2. `answer` (str): concise, factual answer\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## context ## ]]\n",
      "{context}\n",
      "\n",
      "[[ ## question ## ]]\n",
      "{question}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## answer ## ]]\n",
      "{answer}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "In adhering to this structure, your objective is: \n",
      "        Answer questions using the provided context from Wikipedia.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "This is an example of the task, though some input or output fields are not supplied.\n",
      "\n",
      "[[ ## question ## ]]\n",
      "What is the boiling point of Nitrogen?\n",
      "\n",
      "\n",
      "\u001b[31mAssistant message:\u001b[0m\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "Not supplied for this particular example. \n",
      "\n",
      "[[ ## answer ## ]]\n",
      "-195.79 °C\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## context ## ]]\n",
      "[The Great Gatsby (1974 film)]: The Great Gatsby is a 1974 American historical romantic drama film based on the 1925 novel by F. Scott Fitzgerald. The film was directed by Jack Clayton, produced by David Merrick, and written by Francis Ford Coppola. It stars Robert Redford, Mia Farrow, Sam Waterston, Bruce Dern, and Karen Black. The plot concerns the interactions of writer Nick Carraway with enigmatic millionaire Jay Gatsby (Redford) and Gatsby's obsession to reunite with his former lover, Daisy Buchanan (Farrow), amid the riotous parties of the Jazz Age on Long Island near New York City.\n",
      "The Great Gatsby was preceded by 1926 and 1949 films of the same name.\n",
      "\n",
      "[The Great Gatsby (2013 film)]: The Great Gatsby is a 2013 historical romantic drama film based on the 1925 novel by F. Scott Fitzgerald. The film was co-written and directed by Baz Luhrmann and stars an ensemble cast consisting of Leonardo DiCaprio, Tobey Maguire, Carey Mulligan, Joel Edgerton, Isla Fisher, Jason Clarke, and Elizabeth Debicki. Filming took place from September to December 2011 in Australia, with a $105 million net production budget. The film follows the life and times of millionaire Jay Gatsby (DiCaprio) and his neighbor Nick Carraway (Maguire) who recounts his interactions with Gatsby amid the riotous parties of the Jazz Age on Long Island in New York.\n",
      "A polarizing film among critics, The Great Gatsby received both praise and criticism for its visual style, direction, performances, soundtrack, and interpretation of the source material.\n",
      "\n",
      "[The Great Gatsby]: The Great Gatsby ( ) is a 1925 tragedy novel by American writer F. Scott Fitzgerald. Set in the Jazz Age on Long Island, near New York City, the novel depicts first-person narrator Nick Carraway's interactions with Jay Gatsby, a mysterious millionaire obsessed with reuniting with his former lover, Daisy Buchanan.\n",
      "The novel was inspired by a youthful romance Fitzgerald had with socialite Ginevra King and the riotous parties he attended on Long Island's North Shore in 1922. Following a move to the French Riviera, Fitzgerald completed a rough draft of the novel in 1924. He submitted it to editor Maxwell Perkins, who persuaded Fitzgerald to revise the work over the following winter.\n",
      "\n",
      "[The Great Gatsby (1926 film)]: The Great Gatsby is a 1926 American silent drama film directed by Herbert Brenon. It was the first film adaptation of the 1925 novel of the same name by F. Scott Fitzgerald. Warner Baxter portrayed Jay Gatsby, Lois Wilson portrayed Daisy Buchanan and Neil Hamilton portrayed Nick Carraway. The film was produced by Famous Players–Lasky, and distributed by Paramount Pictures.\n",
      "The Great Gatsby is now considered lost.\n",
      "\n",
      "[Adaptations of The Great Gatsby]: The Great Gatsby is a 1925 novel written by American author F. Scott Fitzgerald set during the Jazz Age on Long Island. Since its first publication in 1925, the novel has been widely considered to be a literary masterwork and a contender for the title of the Great American Novel. It has been adapted across various media, including stage, film, television, radio, literature, graphic novels, and video games.\n",
      "The earliest adaptation occurred with a 1926 Broadway play directed by George Cukor and starring James Rennie and Florence Eldridge. Subsequent stage productions included musicals, such as a 1956 production by the Yale Dramatic Association and several Broadway shows.\n",
      "\n",
      "[[ ## question ## ]]\n",
      "Who wrote 'The Great Gatsby'?\n",
      "\n",
      "\n",
      "\u001b[31mAssistant message:\u001b[0m\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The question asks for the author of the novel 'The Great Gatsby'. The context provided includes information about the novel, its adaptations, and film versions. The relevant information is found in the section titled '[The Great Gatsby]', which states that 'The Great Gatsby' is a 1925 tragedy novel by American writer F. Scott Fitzgerald.\n",
      "\n",
      "[[ ## answer ## ]]\n",
      "F. Scott Fitzgerald\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## context ## ]]\n",
      "[Kazakhstan]: Kazakhstan, officially the Republic of Kazakhstan, is a landlocked country primarily in Central Asia, with a small portion in Eastern Europe. It borders Russia to the north and west, China to the east, Kyrgyzstan to the southeast, Uzbekistan to the south, and Turkmenistan to the southwest, with a coastline along the Caspian Sea. Its capital is Astana, while the largest city and leading cultural and commercial hub is Almaty (which had been the capital city until 1997).\n",
      "Kazakhstan is the world's ninth-largest country by land area and the largest landlocked country. Hilly plateaus and plains account for nearly half its vast territory, with lowlands composing another third; its southern and eastern frontiers are composed of mountainous regions.\n",
      "\n",
      "[Economy of Kazakhstan]: The economy of Kazakhstan is the largest in Central Asia in both absolute and per capita terms. As of 2023, Kazakhstan attracted more than US$370 billion of foreign investments since becoming an independent republic after the dissolution of the former Soviet Union.\n",
      "It possesses oil reserves as well as minerals and metals. Almost every known element on the periodic table can be found in Kazakhstan. It also has considerable agricultural potential, with its vast steppe lands accommodating both livestock and grain production.\n",
      "\n",
      "[Russians in Kazakhstan]: There has been a substantial population since the 19th century of Russian Kazakhstanis, or simply Russian Kazakhs, who are ethnic Russians living as citizens in Kazakhstan. Russians formed a plurality of the Kazakh SSR's population for several decades. Although their numbers have been reduced since the breakup of the Soviet Union, they remain prominent in Kazakh society today.\n",
      "\n",
      "\n",
      "== Early colonisation ==\n",
      "The first Rusʹ traders and soldiers began to appear on the northwestern edge of modern Kazakhstan territory in the early 16th century, when Cossacks established the forts that later became the cities of Oral (Uralʹsk, est. 1520) and Atyrau (Gurʹyev).\n",
      "\n",
      "[Kazakhstan–Russia border]: The Kazakhstan–Russia border is the 7,644-kilometre (4,750 mi) international border between the Republic of Kazakhstan and the Russian Federation. It is the longest continuous international border in the world and the second longest by total length, after the Canada–United States border. It is in the same location as the former administrative-territorial border between the Kazakh Soviet Socialist Republic and the Russian Soviet Federative Socialist Republic.\n",
      "\n",
      "\n",
      "== Geography ==\n",
      "The border starts in the west at the Caspian Sea and runs in a broadly west–east direction to the tripoint with China, though in places it is extremely convoluted. The border consists almost entirely of a series of overland lines traversing the Eurasian Steppe, though in sections rivers are utilised, such as the Maly Uzen, Ural and Uy.\n",
      "\n",
      "[Capital punishment]: Capital punishment, also known as the death penalty and formerly called judicial homicide, is the state-sanctioned killing of a person as punishment for actual or supposed misconduct. The sentence ordering that an offender be punished in such a manner is called a death sentence, and the act of carrying out the sentence is an execution. A prisoner who has been sentenced to death and awaits execution is condemned and is commonly referred to as being \"on death row\". Etymologically, the term capital (lit. 'of the head', derived via the Latin capitalis from caput, \"head\") refers to execution by beheading, but executions are carried out by many methods.\n",
      "Crimes that are punishable by death are known as capital crimes, capital offences, or capital felonies, and vary depending on the jurisdiction, but commonly include serious crimes against a person, such as murder, assassination, mass murder, child murder, aggravated rape, terrorism, aircraft hijacking, war crimes, crimes against humanity, and genocide, along with crimes against the state such as attempting to overthrow government, treason, espionage, sedition, and piracy.\n",
      "\n",
      "[[ ## question ## ]]\n",
      "What is the capital of Kazakhstan?\n",
      "\n",
      "\n",
      "\u001b[31mAssistant message:\u001b[0m\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The context provided contains information about Kazakhstan, including its geography, economy, and history. The question asks for the capital of Kazakhstan, which is mentioned in the section about Kazakhstan. According to the text, the capital of Kazakhstan is Astana.\n",
      "\n",
      "[[ ## answer ## ]]\n",
      "Astana\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## context ## ]]\n",
      "[Solar System]: The Solar System is the gravitationally bound system of the Sun and the masses that orbit it, most prominently its eight planets, of which Earth is one. The system formed about 4.6 billion years ago when a dense region of a molecular cloud collapsed, creating the Sun and a protoplanetary disc from which the orbiting bodies assembled. Inside the Sun's core hydrogen is fused into helium for billions of years, releasing energy which is over even longer periods of time emitted through the Sun's outer layer, the photosphere. This creates the heliosphere and a decreasing temperature gradient across the Solar System.\n",
      "The mass of the Solar System is by 99.86% almost completely made up of the Sun's mass.\n",
      "\n",
      "[Sun]: The Sun is the star at the centre of the Solar System. It is a massive, nearly perfect sphere of hot plasma, heated to incandescence by nuclear fusion reactions in its core, radiating the energy from its surface mainly as visible light and infrared radiation with 10% at ultraviolet energies. It is the main source of energy for life on Earth. The Sun has been an object of veneration in many cultures and a central subject for astronomical research since antiquity.\n",
      "The Sun orbits the Galactic Center at a distance of 24,000 to 28,000 light-years.\n",
      "\n",
      "[Planet]: A planet is a large, rounded astronomical body that is generally required to be in orbit around a star, stellar remnant, or brown dwarf, and is not one itself. The Solar System has eight planets by the most restrictive definition of the term: the terrestrial planets Mercury, Venus, Earth, and Mars, and the giant planets Jupiter, Saturn, Uranus, and Neptune. The best available theory of planet formation is the nebular hypothesis, which posits that an interstellar cloud collapses out of a nebula to create a young protostar orbited by a protoplanetary disk. Planets grow in this disk by the gradual accumulation of material driven by gravity, a process called accretion.\n",
      "The word planet comes from the Greek πλανήται (planḗtai) 'wanderers'.\n",
      "\n",
      "[List of hottest exoplanets]: This is a list of the hottest exoplanets so far discovered, specifically those with temperatures greater than 2500 K (2230 °C; 4040 °F) for exoplanets irradiated by a nearby star and greater than 2000 K (1730 °C; 3140 °F) for self-luminous exoplanets. For comparison, the hottest planet in the Solar System is Venus, with a temperature of 737 K (464 °C; 867 °F).\n",
      "\n",
      "\n",
      "== List of hottest exoplanets irradiated by a nearby star ==\n",
      "\n",
      "Methods for finding temperature:\n",
      "\n",
      "Teff: Measured effective temperature.\n",
      "Teq: The temperature of the planet has not been measured, so it is listed with the calculated equilibrium temperature.\n",
      "\n",
      "\n",
      "== List of hottest self-luminous exoplanets ==\n",
      "\n",
      "All these are measured temperatures.\n",
      "\n",
      "[Formation and evolution of the Solar System]: There is evidence that the formation of the Solar System began about 4.6 billion years ago with the gravitational collapse of a small part of a giant molecular cloud. Most of the collapsing mass collected in the center, forming the Sun, while the rest flattened into a protoplanetary disk out of which the planets, moons, asteroids, and other small Solar System bodies formed.\n",
      "This model, known as the nebular hypothesis, was first developed in the 18th century by Emanuel Swedenborg, Immanuel Kant, and Pierre-Simon Laplace. Its subsequent development has interwoven a variety of scientific disciplines including astronomy, chemistry, geology, physics, and planetary science. Since the dawn of the Space Age in the 1950s and the discovery of exoplanets in the 1990s, the model has been both challenged and refined to account for new observations.\n",
      "\n",
      "[[ ## question ## ]]\n",
      "Which planet is the hottest in our solar system?\n",
      "\n",
      "\n",
      "\u001b[31mAssistant message:\u001b[0m\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The context provided includes a section on the list of hottest exoplanets, but it also mentions the hottest planet in our Solar System. According to the given information, the hottest planet in the Solar System is Venus, with a temperature of 737 K (464 °C; 867 °F).\n",
      "\n",
      "[[ ## answer ## ]]\n",
      "Venus\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## context ## ]]\n",
      "[Telephone]: A telephone, commonly shortened to phone, is a telecommunications device that enables two or more users to conduct a conversation when they are too far apart to be easily heard directly. A telephone converts sound, typically and most efficiently the human voice, into electronic signals that are transmitted via cables and other communication channels to another telephone which reproduces the sound to the receiving user. The term is derived from Ancient Greek: τῆλε, romanized: tēle, lit. 'far' and φωνή (phōnē, voice), together meaning distant voice.\n",
      "In 1876, Alexander Graham Bell was the first to be granted a United States patent for a device that produced clearly intelligible replication of the human voice at a second device. This instrument was further developed by many others, and became rapidly indispensable in business, government, and in households.\n",
      "\n",
      "[Antonio Meucci]: Antonio Santi Giuseppe Meucci ( may-OO-chee, Italian: [anˈtɔːnjo meˈuttʃi]; 13 April 1808 – 18 October 1889) was an Italian inventor and an associate of Giuseppe Garibaldi, a major political figure in the history of Italy. Meucci is best known for developing a voice-communication apparatus that several sources credit as the first telephone.  \n",
      "Meucci set up a form of voice-communication link in his Staten Island, New York, home that connected the second-floor bedroom to his laboratory. He submitted a patent caveat for his telephonic device to the U.S. Patent Office in 1871, but there was no mention of electromagnetic transmission of vocal sound in his caveat. In 1876, Alexander Graham Bell was granted a patent for the electromagnetic transmission of vocal sound by undulatory electric current.\n",
      "\n",
      "[Alexander Graham Bell]: Alexander Graham Bell ( ; born Alexander Bell; March 3, 1847 – August 2, 1922) was a  Scottish-born Canadian-American inventor, scientist, and engineer who is credited with patenting the first practical telephone. He also co-founded the American Telephone and Telegraph Company (AT&T) in 1885.\n",
      "Bell's father, grandfather, and brother had all been associated with work on elocution and speech, and both his mother and wife were deaf, profoundly influencing Bell's life's work. His research on hearing and speech further led him to experiment with hearing devices, which eventually culminated in his being awarded the first U.S. patent for the telephone, on March 7, 1876. Bell considered his invention an intrusion on his real work as a scientist and refused to have a telephone in his study.\n",
      "\n",
      "[The Telephone Cases]: The Telephone Cases, 126 U.S. 1 (1888), were a series of U.S. court cases in the 1870s and the 1880s related to the invention of the telephone, which culminated in an 1888 decision of the U.S. Supreme Court that upheld the priority of the patents belonging to Alexander Graham Bell. Those patents were used by the American Bell Telephone Company and the Bell System, although they had also acquired critical microphone patents from Emile Berliner.\n",
      "The objector (or plaintiff) in the Supreme Court case was initially the Western Union telegraph company, which was then a far-larger and better financed competitor than American Bell Telephone. Western Union advocated several more recent patent claims of Daniel Drawbaugh, Elisha Gray, Antonio Meucci, and Philip Reis in a bid to invalidate Alexander Graham Bell's master and subsidiary telephone patents dating from March 1876. A decision for Western Union would have immediately destroyed the Bell Telephone Company, and might have allowed the former company, instead of the latter, to become the world's largest telecommunications monopoly.\n",
      "\n",
      "[Reis telephone]: The Reis telephone was an early sound transmitting device, invented by Philipp Reis in 1857.  Reis's first successful work is dated to October 1861. When properly set up, it would allow verbal communication via electronic signals. Many sources credit Reis as the inventor of the first telephone.  Others point to the prior work of Antonio Meucci, or to later work of Elisha Gray or Alexander Graham Bell.\n",
      "\n",
      "[[ ## question ## ]]\n",
      "Who invented the telephone?\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## answer ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## reasoning ## ]]\n",
      "The question of who invented the telephone is a matter of debate, with several individuals contributing to its development. According to the context, Alexander Graham Bell is often credited with patenting the first practical telephone and is widely recognized as its inventor. However, others, such as Antonio Meucci and Philipp Reis, also worked on early versions of the telephone and are sometimes credited with its invention. The context also mentions that the Telephone Cases, a series of court cases, ultimately upheld the priority of Bell's patents. Considering the information provided, it can be concluded that Alexander Graham Bell is the most widely recognized inventor of the telephone, but it is also important to acknowledge the contributions of other individuals.\n",
      "\n",
      "[[ ## answer ## ]]\n",
      "Alexander Graham Bell\n",
      "\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import dspy\n",
    "import wikipedia\n",
    "from dspy.teleprompt import BootstrapFewShot\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings during execution\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 2. THE RETRIEVER: Custom Wikipedia Function\n",
    "def search_wikipedia(query: str, k=5) -> list[str]:\n",
    "    \"\"\"Real-time Wikipedia abstracts for RAG.\"\"\"\n",
    "    try:\n",
    "        # Search for more results to get better coverage\n",
    "        titles = wikipedia.search(query, results=k)\n",
    "        contexts = []\n",
    "        for title in titles:\n",
    "            try:\n",
    "                # Get a longer summary (5 sentences) for better context\n",
    "                summary = wikipedia.summary(title, sentences=5, auto_suggest=False)\n",
    "                contexts.append(f\"[{title}]: {summary}\")\n",
    "            except Exception as e:\n",
    "                continue\n",
    "        return contexts if contexts else [\"No relevant Wikipedia context found.\"]\n",
    "    except Exception as e:\n",
    "        return [f\"Error connecting to Wikipedia: {str(e)}\"]\n",
    "\n",
    "# 3. THE PROGRAM: Define RAG Signature and Module\n",
    "class RAGSignature(dspy.Signature):\n",
    "    \"\"\"Answer questions using the provided context from Wikipedia.\"\"\"\n",
    "    context = dspy.InputField(desc=\"Wikipedia snippets\")\n",
    "    question = dspy.InputField()\n",
    "    answer = dspy.OutputField(desc=\"concise, factual answer\")\n",
    "\n",
    "class RAG(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # ChainOfThought adds a 'reasoning' step before the answer\n",
    "        self.generate_answer = dspy.ChainOfThought(RAGSignature)\n",
    "    \n",
    "    def forward(self, question):\n",
    "        context = search_wikipedia(question)\n",
    "        # Join contexts into a single string\n",
    "        context_str = \"\\n\\n\".join(context) if isinstance(context, list) else context\n",
    "        prediction = self.generate_answer(context=context_str, question=question)\n",
    "        \n",
    "        # Why dspy.Prediction instead of just returning prediction.answer?\n",
    "        # - OutputField defines what the signature outputs (just 'answer')\n",
    "        # - But we need to return BOTH 'answer' AND 'context' (context is not in signature)\n",
    "        # - dspy.Prediction allows returning multiple fields beyond the signature\n",
    "        # - This is useful for debugging, inspection, and downstream processing\n",
    "        return dspy.Prediction(context=context_str, answer=prediction.answer)\n",
    "        \n",
    "\n",
    "# 4. DATASET: Create a Synthetic Training Set\n",
    "trainset = [\n",
    "    dspy.Example(question=\"What is the boiling point of Nitrogen?\", answer=\"-195.79 °C\").with_inputs('question'),\n",
    "    dspy.Example(question=\"Who wrote 'The Great Gatsby'?\", answer=\"F. Scott Fitzgerald\").with_inputs('question'),\n",
    "    dspy.Example(question=\"What is the capital of Kazakhstan?\", answer=\"Astana\").with_inputs('question'),\n",
    "    dspy.Example(question=\"Which planet is the hottest in our solar system?\", answer=\"Venus\").with_inputs('question')\n",
    "]\n",
    "\n",
    "# 5. OPTIMIZATION: Compile the Program\n",
    "def validate_answer(example, pred, trace=None):\n",
    "    \"\"\"Metric: Does the predicted answer match the ground truth?\"\"\"\n",
    "    return dspy.evaluate.answer_exact_match(example, pred)\n",
    "\n",
    "# Teleprompter simulates traces to find best few-shot examples\n",
    "print(\"Compiling RAG program with BootstrapFewShot...\")\n",
    "teleprompter = BootstrapFewShot(\n",
    "    metric=validate_answer, \n",
    "    max_bootstrapped_demos=3,\n",
    "    max_labeled_demos=4\n",
    ")\n",
    "compiled_rag = teleprompter.compile(RAG(), trainset=trainset)\n",
    "print(\"✓ Compilation complete!\\n\")\n",
    "\n",
    "# 6. EVALUATION: Compare Before vs. After\n",
    "def run_comparison(question):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Baseline (Unoptimized)\n",
    "    print(\"\\n[Baseline - Unoptimized]\")\n",
    "    baseline_rag = RAG()\n",
    "    baseline_output = baseline_rag(question)\n",
    "    print(f\"Answer: {baseline_output.answer}\")\n",
    "    if hasattr(baseline_output, 'context'):\n",
    "        print(f\"Context snippets: {len(baseline_output.context.split('['))-1 if '[' in baseline_output.context else 1}\")\n",
    "    \n",
    "    # Optimized (Compiled)\n",
    "    print(\"\\n[Optimized - Compiled with BootstrapFewShot]\")\n",
    "    optimized_output = compiled_rag(question)\n",
    "    print(f\"Answer: {optimized_output.answer}\")\n",
    "    if hasattr(optimized_output, 'context'):\n",
    "        print(f\"Context snippets: {len(optimized_output.context.split('['))-1 if '[' in optimized_output.context else 1}\")\n",
    "\n",
    "# Test with multiple queries\n",
    "test_questions = [\n",
    "    \"Who won the Nobel Prize in Literature in 2006 and what is their country?\",\n",
    "    \"What is the capital of France?\",\n",
    "    \"Who invented the telephone?\"\n",
    "]\n",
    "\n",
    "for q in test_questions:\n",
    "    run_comparison(q)\n",
    "\n",
    "# 7. INSPECTION: See how the prompt changed\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"OPTIMIZED PROMPT LOG (Full History)\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nShowing last prompt interaction:\")\n",
    "dspy.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0535bafd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "1. BASELINE PROMPT (Before Optimization)\n",
      "======================================================================\n",
      "\n",
      "Baseline Prompt Structure:\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2026-01-20T02:14:38.796575]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `context` (str): Wikipedia snippets\n",
      "2. `question` (str):\n",
      "Your output fields are:\n",
      "1. `reasoning` (str): \n",
      "2. `answer` (str): concise, factual answer\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## context ## ]]\n",
      "{context}\n",
      "\n",
      "[[ ## question ## ]]\n",
      "{question}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## answer ## ]]\n",
      "{answer}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "In adhering to this structure, your objective is: \n",
      "        Answer questions using the provided context from Wikipedia.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## context ## ]]\n",
      "[Closed-ended question]: A closed-ended question is any question for which a researcher provides research participants with options from which to choose a response. Closed-ended questions are sometimes phrased as a statement that requires a response.\n",
      "A closed-ended question contrasts with an open-ended question, which cannot easily be answered with specific information.\n",
      "\n",
      "\n",
      "== Examples ==\n",
      "Examples of closed-ended questions that may elicit a \"yes\" or \"no\" response include:\n",
      "\n",
      "Were you born in 2010?\n",
      "Is Lyon the capital of France?\n",
      "\n",
      "[France]: France, officially the French Republic, is a country primarily located in Western Europe. Its overseas regions and territories include French Guiana in South America, Saint Pierre and Miquelon in the North Atlantic, the French West Indies, and many islands in Oceania and the Indian Ocean. Metropolitan France shares borders with Belgium and Luxembourg to the north; Germany to the northeast; Switzerland to the east; Italy and Monaco to the southeast; Andorra and Spain to the south; and a maritime border with the United Kingdom to the northwest. Its metropolitan area extends from the Rhine to the Atlantic Ocean and from the Mediterranean Sea to the English Channel and the North Sea. Its 18 integral regions—five of which are overseas—span a combined area of 632,702 km2 (244,288 sq mi), with a total population estimated at over 68 million in 2025.\n",
      "\n",
      "[What Is a Nation?]: \"What Is a Nation?\" (French: Qu'est-ce qu'une nation ?) is an 1882 lecture by French historian Ernest Renan (1823–1892) at the Sorbonne, known for the statements that a nation is \"a daily plebiscite\", and that nations are based as much on what people jointly forget as on what they remember.  It is frequently quoted or anthologized in works of history or political science pertaining to nationalism and national identity. It exemplifies   a contractualist understanding of the nation.\n",
      "\n",
      "\n",
      "== Nationhood in Renan's time ==\n",
      "Renan begins his essay by noting that there is frequent confusion between the idea of nationhood and of racial or linguistic groupings, a form of confusion which he says can produce \"the gravest errors\". He promises to conduct an autopsy-like examination, \"in an absolutely cold and impartial fashion.\"\n",
      "He claims that nations existing at the time of writing in 1882, such as France, Germany, the United Kingdom, and Russia, will continue to exist for hundreds of years, and that any nation trying to dominate them will be quickly pushed back to its own borders,  by a coalition of other nations; \"The establishment of a new Roman or Charlemagnian Empire has become an impossibility.\"\n",
      "Renan believes that nations developed from the common needs of the people, who consisted of different social groups seeking a \"collective identity\".\n",
      "\n",
      "[Capital punishment]: Capital punishment, also known as the death penalty and formerly called judicial homicide, is the state-sanctioned killing of a person as punishment for actual or supposed misconduct. The sentence ordering that an offender be punished in such a manner is called a death sentence, and the act of carrying out the sentence is an execution. A prisoner who has been sentenced to death and awaits execution is condemned and is commonly referred to as being \"on death row\". Etymologically, the term capital (lit. 'of the head', derived via the Latin capitalis from caput, \"head\") refers to execution by beheading, but executions are carried out by many methods.\n",
      "Crimes that are punishable by death are known as capital crimes, capital offences, or capital felonies, and vary depending on the jurisdiction, but commonly include serious crimes against a person, such as murder, assassination, mass murder, child murder, aggravated rape, terrorism, aircraft hijacking, war crimes, crimes against humanity, and genocide, along with crimes against the state such as attempting to overthrow government, treason, espionage, sedition, and piracy.\n",
      "\n",
      "[WhatsApp]: WhatsApp Messenger, commonly known simply as WhatsApp, is an American social media, instant messaging (IM), and Voice over IP (VoIP) service accessible via desktop and mobile app. Owned by Meta Platforms, the service allows users to send text messages, voice messages, and video messages, make voice and video calls, and share images, documents, user locations, and other content. The service requires a cellular mobile telephone number to register. WhatsApp was launched in May 2009. In January 2018, WhatsApp released a standalone business app called WhatsApp Business which can communicate with the standard WhatsApp client.\n",
      "\n",
      "[[ ## question ## ]]\n",
      "What is the capital of France?\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## answer ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## reasoning ## ]]\n",
      "To answer this question, we need to look at the provided context. The context includes information about France, including its geography and borders. However, it does not explicitly state what the capital of France is. But, we can find a clue in the section about closed-ended questions, where it provides an example of a closed-ended question: \"Is Lyon the capital of France?\" This implies that Lyon is not the capital, as the question is asking for confirmation. Given that the context does not provide a direct answer, we must rely on general knowledge or find a hint within the text. Since the text does not directly state the capital, we must use external knowledge to determine that the capital of France is indeed Paris, although Paris is not mentioned in the provided context.\n",
      "\n",
      "[[ ## answer ## ]]\n",
      "Paris\n",
      "\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "======================================================================\n",
      "2. OPTIMIZED PROMPT (After BootstrapFewShot)\n",
      "======================================================================\n",
      "\n",
      "Optimized Prompt Structure:\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2026-01-20T02:14:38.799309]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `context` (str): Wikipedia snippets\n",
      "2. `question` (str):\n",
      "Your output fields are:\n",
      "1. `reasoning` (str): \n",
      "2. `answer` (str): concise, factual answer\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## context ## ]]\n",
      "{context}\n",
      "\n",
      "[[ ## question ## ]]\n",
      "{question}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## answer ## ]]\n",
      "{answer}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "In adhering to this structure, your objective is: \n",
      "        Answer questions using the provided context from Wikipedia.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "This is an example of the task, though some input or output fields are not supplied.\n",
      "\n",
      "[[ ## question ## ]]\n",
      "What is the boiling point of Nitrogen?\n",
      "\n",
      "\n",
      "\u001b[31mAssistant message:\u001b[0m\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "Not supplied for this particular example. \n",
      "\n",
      "[[ ## answer ## ]]\n",
      "-195.79 °C\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## context ## ]]\n",
      "[The Great Gatsby (1974 film)]: The Great Gatsby is a 1974 American historical romantic drama film based on the 1925 novel by F. Scott Fitzgerald. The film was directed by Jack Clayton, produced by David Merrick, and written by Francis Ford Coppola. It stars Robert Redford, Mia Farrow, Sam Waterston, Bruce Dern, and Karen Black. The plot concerns the interactions of writer Nick Carraway with enigmatic millionaire Jay Gatsby (Redford) and Gatsby's obsession to reunite with his former lover, Daisy Buchanan (Farrow), amid the riotous parties of the Jazz Age on Long Island near New York City.\n",
      "The Great Gatsby was preceded by 1926 and 1949 films of the same name.\n",
      "\n",
      "[The Great Gatsby (2013 film)]: The Great Gatsby is a 2013 historical romantic drama film based on the 1925 novel by F. Scott Fitzgerald. The film was co-written and directed by Baz Luhrmann and stars an ensemble cast consisting of Leonardo DiCaprio, Tobey Maguire, Carey Mulligan, Joel Edgerton, Isla Fisher, Jason Clarke, and Elizabeth Debicki. Filming took place from September to December 2011 in Australia, with a $105 million net production budget. The film follows the life and times of millionaire Jay Gatsby (DiCaprio) and his neighbor Nick Carraway (Maguire) who recounts his interactions with Gatsby amid the riotous parties of the Jazz Age on Long Island in New York.\n",
      "A polarizing film among critics, The Great Gatsby received both praise and criticism for its visual style, direction, performances, soundtrack, and interpretation of the source material.\n",
      "\n",
      "[The Great Gatsby]: The Great Gatsby ( ) is a 1925 tragedy novel by American writer F. Scott Fitzgerald. Set in the Jazz Age on Long Island, near New York City, the novel depicts first-person narrator Nick Carraway's interactions with Jay Gatsby, a mysterious millionaire obsessed with reuniting with his former lover, Daisy Buchanan.\n",
      "The novel was inspired by a youthful romance Fitzgerald had with socialite Ginevra King and the riotous parties he attended on Long Island's North Shore in 1922. Following a move to the French Riviera, Fitzgerald completed a rough draft of the novel in 1924. He submitted it to editor Maxwell Perkins, who persuaded Fitzgerald to revise the work over the following winter.\n",
      "\n",
      "[The Great Gatsby (1926 film)]: The Great Gatsby is a 1926 American silent drama film directed by Herbert Brenon. It was the first film adaptation of the 1925 novel of the same name by F. Scott Fitzgerald. Warner Baxter portrayed Jay Gatsby, Lois Wilson portrayed Daisy Buchanan and Neil Hamilton portrayed Nick Carraway. The film was produced by Famous Players–Lasky, and distributed by Paramount Pictures.\n",
      "The Great Gatsby is now considered lost.\n",
      "\n",
      "[Adaptations of The Great Gatsby]: The Great Gatsby is a 1925 novel written by American author F. Scott Fitzgerald set during the Jazz Age on Long Island. Since its first publication in 1925, the novel has been widely considered to be a literary masterwork and a contender for the title of the Great American Novel. It has been adapted across various media, including stage, film, television, radio, literature, graphic novels, and video games.\n",
      "The earliest adaptation occurred with a 1926 Broadway play directed by George Cukor and starring James Rennie and Florence Eldridge. Subsequent stage productions included musicals, such as a 1956 production by the Yale Dramatic Association and several Broadway shows.\n",
      "\n",
      "[[ ## question ## ]]\n",
      "Who wrote 'The Great Gatsby'?\n",
      "\n",
      "\n",
      "\u001b[31mAssistant message:\u001b[0m\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The question asks for the author of the novel 'The Great Gatsby'. The context provided includes information about the novel, its adaptations, and film versions. The relevant information is found in the section titled '[The Great Gatsby]', which states that 'The Great Gatsby' is a 1925 tragedy novel by American writer F. Scott Fitzgerald.\n",
      "\n",
      "[[ ## answer ## ]]\n",
      "F. Scott Fitzgerald\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## context ## ]]\n",
      "[Kazakhstan]: Kazakhstan, officially the Republic of Kazakhstan, is a landlocked country primarily in Central Asia, with a small portion in Eastern Europe. It borders Russia to the north and west, China to the east, Kyrgyzstan to the southeast, Uzbekistan to the south, and Turkmenistan to the southwest, with a coastline along the Caspian Sea. Its capital is Astana, while the largest city and leading cultural and commercial hub is Almaty (which had been the capital city until 1997).\n",
      "Kazakhstan is the world's ninth-largest country by land area and the largest landlocked country. Hilly plateaus and plains account for nearly half its vast territory, with lowlands composing another third; its southern and eastern frontiers are composed of mountainous regions.\n",
      "\n",
      "[Economy of Kazakhstan]: The economy of Kazakhstan is the largest in Central Asia in both absolute and per capita terms. As of 2023, Kazakhstan attracted more than US$370 billion of foreign investments since becoming an independent republic after the dissolution of the former Soviet Union.\n",
      "It possesses oil reserves as well as minerals and metals. Almost every known element on the periodic table can be found in Kazakhstan. It also has considerable agricultural potential, with its vast steppe lands accommodating both livestock and grain production.\n",
      "\n",
      "[Russians in Kazakhstan]: There has been a substantial population since the 19th century of Russian Kazakhstanis, or simply Russian Kazakhs, who are ethnic Russians living as citizens in Kazakhstan. Russians formed a plurality of the Kazakh SSR's population for several decades. Although their numbers have been reduced since the breakup of the Soviet Union, they remain prominent in Kazakh society today.\n",
      "\n",
      "\n",
      "== Early colonisation ==\n",
      "The first Rusʹ traders and soldiers began to appear on the northwestern edge of modern Kazakhstan territory in the early 16th century, when Cossacks established the forts that later became the cities of Oral (Uralʹsk, est. 1520) and Atyrau (Gurʹyev).\n",
      "\n",
      "[Kazakhstan–Russia border]: The Kazakhstan–Russia border is the 7,644-kilometre (4,750 mi) international border between the Republic of Kazakhstan and the Russian Federation. It is the longest continuous international border in the world and the second longest by total length, after the Canada–United States border. It is in the same location as the former administrative-territorial border between the Kazakh Soviet Socialist Republic and the Russian Soviet Federative Socialist Republic.\n",
      "\n",
      "\n",
      "== Geography ==\n",
      "The border starts in the west at the Caspian Sea and runs in a broadly west–east direction to the tripoint with China, though in places it is extremely convoluted. The border consists almost entirely of a series of overland lines traversing the Eurasian Steppe, though in sections rivers are utilised, such as the Maly Uzen, Ural and Uy.\n",
      "\n",
      "[Capital punishment]: Capital punishment, also known as the death penalty and formerly called judicial homicide, is the state-sanctioned killing of a person as punishment for actual or supposed misconduct. The sentence ordering that an offender be punished in such a manner is called a death sentence, and the act of carrying out the sentence is an execution. A prisoner who has been sentenced to death and awaits execution is condemned and is commonly referred to as being \"on death row\". Etymologically, the term capital (lit. 'of the head', derived via the Latin capitalis from caput, \"head\") refers to execution by beheading, but executions are carried out by many methods.\n",
      "Crimes that are punishable by death are known as capital crimes, capital offences, or capital felonies, and vary depending on the jurisdiction, but commonly include serious crimes against a person, such as murder, assassination, mass murder, child murder, aggravated rape, terrorism, aircraft hijacking, war crimes, crimes against humanity, and genocide, along with crimes against the state such as attempting to overthrow government, treason, espionage, sedition, and piracy.\n",
      "\n",
      "[[ ## question ## ]]\n",
      "What is the capital of Kazakhstan?\n",
      "\n",
      "\n",
      "\u001b[31mAssistant message:\u001b[0m\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The context provided contains information about Kazakhstan, including its geography, economy, and history. The question asks for the capital of Kazakhstan, which is mentioned in the section about Kazakhstan. According to the text, the capital of Kazakhstan is Astana.\n",
      "\n",
      "[[ ## answer ## ]]\n",
      "Astana\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## context ## ]]\n",
      "[Solar System]: The Solar System is the gravitationally bound system of the Sun and the masses that orbit it, most prominently its eight planets, of which Earth is one. The system formed about 4.6 billion years ago when a dense region of a molecular cloud collapsed, creating the Sun and a protoplanetary disc from which the orbiting bodies assembled. Inside the Sun's core hydrogen is fused into helium for billions of years, releasing energy which is over even longer periods of time emitted through the Sun's outer layer, the photosphere. This creates the heliosphere and a decreasing temperature gradient across the Solar System.\n",
      "The mass of the Solar System is by 99.86% almost completely made up of the Sun's mass.\n",
      "\n",
      "[Sun]: The Sun is the star at the centre of the Solar System. It is a massive, nearly perfect sphere of hot plasma, heated to incandescence by nuclear fusion reactions in its core, radiating the energy from its surface mainly as visible light and infrared radiation with 10% at ultraviolet energies. It is the main source of energy for life on Earth. The Sun has been an object of veneration in many cultures and a central subject for astronomical research since antiquity.\n",
      "The Sun orbits the Galactic Center at a distance of 24,000 to 28,000 light-years.\n",
      "\n",
      "[Planet]: A planet is a large, rounded astronomical body that is generally required to be in orbit around a star, stellar remnant, or brown dwarf, and is not one itself. The Solar System has eight planets by the most restrictive definition of the term: the terrestrial planets Mercury, Venus, Earth, and Mars, and the giant planets Jupiter, Saturn, Uranus, and Neptune. The best available theory of planet formation is the nebular hypothesis, which posits that an interstellar cloud collapses out of a nebula to create a young protostar orbited by a protoplanetary disk. Planets grow in this disk by the gradual accumulation of material driven by gravity, a process called accretion.\n",
      "The word planet comes from the Greek πλανήται (planḗtai) 'wanderers'.\n",
      "\n",
      "[List of hottest exoplanets]: This is a list of the hottest exoplanets so far discovered, specifically those with temperatures greater than 2500 K (2230 °C; 4040 °F) for exoplanets irradiated by a nearby star and greater than 2000 K (1730 °C; 3140 °F) for self-luminous exoplanets. For comparison, the hottest planet in the Solar System is Venus, with a temperature of 737 K (464 °C; 867 °F).\n",
      "\n",
      "\n",
      "== List of hottest exoplanets irradiated by a nearby star ==\n",
      "\n",
      "Methods for finding temperature:\n",
      "\n",
      "Teff: Measured effective temperature.\n",
      "Teq: The temperature of the planet has not been measured, so it is listed with the calculated equilibrium temperature.\n",
      "\n",
      "\n",
      "== List of hottest self-luminous exoplanets ==\n",
      "\n",
      "All these are measured temperatures.\n",
      "\n",
      "[Formation and evolution of the Solar System]: There is evidence that the formation of the Solar System began about 4.6 billion years ago with the gravitational collapse of a small part of a giant molecular cloud. Most of the collapsing mass collected in the center, forming the Sun, while the rest flattened into a protoplanetary disk out of which the planets, moons, asteroids, and other small Solar System bodies formed.\n",
      "This model, known as the nebular hypothesis, was first developed in the 18th century by Emanuel Swedenborg, Immanuel Kant, and Pierre-Simon Laplace. Its subsequent development has interwoven a variety of scientific disciplines including astronomy, chemistry, geology, physics, and planetary science. Since the dawn of the Space Age in the 1950s and the discovery of exoplanets in the 1990s, the model has been both challenged and refined to account for new observations.\n",
      "\n",
      "[[ ## question ## ]]\n",
      "Which planet is the hottest in our solar system?\n",
      "\n",
      "\n",
      "\u001b[31mAssistant message:\u001b[0m\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The context provided includes a section on the list of hottest exoplanets, but it also mentions the hottest planet in our Solar System. According to the given information, the hottest planet in the Solar System is Venus, with a temperature of 737 K (464 °C; 867 °F).\n",
      "\n",
      "[[ ## answer ## ]]\n",
      "Venus\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## context ## ]]\n",
      "[Closed-ended question]: A closed-ended question is any question for which a researcher provides research participants with options from which to choose a response. Closed-ended questions are sometimes phrased as a statement that requires a response.\n",
      "A closed-ended question contrasts with an open-ended question, which cannot easily be answered with specific information.\n",
      "\n",
      "\n",
      "== Examples ==\n",
      "Examples of closed-ended questions that may elicit a \"yes\" or \"no\" response include:\n",
      "\n",
      "Were you born in 2010?\n",
      "Is Lyon the capital of France?\n",
      "\n",
      "[France]: France, officially the French Republic, is a country primarily located in Western Europe. Its overseas regions and territories include French Guiana in South America, Saint Pierre and Miquelon in the North Atlantic, the French West Indies, and many islands in Oceania and the Indian Ocean. Metropolitan France shares borders with Belgium and Luxembourg to the north; Germany to the northeast; Switzerland to the east; Italy and Monaco to the southeast; Andorra and Spain to the south; and a maritime border with the United Kingdom to the northwest. Its metropolitan area extends from the Rhine to the Atlantic Ocean and from the Mediterranean Sea to the English Channel and the North Sea. Its 18 integral regions—five of which are overseas—span a combined area of 632,702 km2 (244,288 sq mi), with a total population estimated at over 68 million in 2025.\n",
      "\n",
      "[What Is a Nation?]: \"What Is a Nation?\" (French: Qu'est-ce qu'une nation ?) is an 1882 lecture by French historian Ernest Renan (1823–1892) at the Sorbonne, known for the statements that a nation is \"a daily plebiscite\", and that nations are based as much on what people jointly forget as on what they remember.  It is frequently quoted or anthologized in works of history or political science pertaining to nationalism and national identity. It exemplifies   a contractualist understanding of the nation.\n",
      "\n",
      "\n",
      "== Nationhood in Renan's time ==\n",
      "Renan begins his essay by noting that there is frequent confusion between the idea of nationhood and of racial or linguistic groupings, a form of confusion which he says can produce \"the gravest errors\". He promises to conduct an autopsy-like examination, \"in an absolutely cold and impartial fashion.\"\n",
      "He claims that nations existing at the time of writing in 1882, such as France, Germany, the United Kingdom, and Russia, will continue to exist for hundreds of years, and that any nation trying to dominate them will be quickly pushed back to its own borders,  by a coalition of other nations; \"The establishment of a new Roman or Charlemagnian Empire has become an impossibility.\"\n",
      "Renan believes that nations developed from the common needs of the people, who consisted of different social groups seeking a \"collective identity\".\n",
      "\n",
      "[Capital punishment]: Capital punishment, also known as the death penalty and formerly called judicial homicide, is the state-sanctioned killing of a person as punishment for actual or supposed misconduct. The sentence ordering that an offender be punished in such a manner is called a death sentence, and the act of carrying out the sentence is an execution. A prisoner who has been sentenced to death and awaits execution is condemned and is commonly referred to as being \"on death row\". Etymologically, the term capital (lit. 'of the head', derived via the Latin capitalis from caput, \"head\") refers to execution by beheading, but executions are carried out by many methods.\n",
      "Crimes that are punishable by death are known as capital crimes, capital offences, or capital felonies, and vary depending on the jurisdiction, but commonly include serious crimes against a person, such as murder, assassination, mass murder, child murder, aggravated rape, terrorism, aircraft hijacking, war crimes, crimes against humanity, and genocide, along with crimes against the state such as attempting to overthrow government, treason, espionage, sedition, and piracy.\n",
      "\n",
      "[WhatsApp]: WhatsApp Messenger, commonly known simply as WhatsApp, is an American social media, instant messaging (IM), and Voice over IP (VoIP) service accessible via desktop and mobile app. Owned by Meta Platforms, the service allows users to send text messages, voice messages, and video messages, make voice and video calls, and share images, documents, user locations, and other content. The service requires a cellular mobile telephone number to register. WhatsApp was launched in May 2009. In January 2018, WhatsApp released a standalone business app called WhatsApp Business which can communicate with the standard WhatsApp client.\n",
      "\n",
      "[[ ## question ## ]]\n",
      "What is the capital of France?\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## answer ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## reasoning ## ]]\n",
      "The context provided includes a section about France, which mentions its location, borders, and metropolitan area. However, it does not explicitly state the capital of France. Nevertheless, another section provides an example of a closed-ended question, \"Is Lyon the capital of France?\" which implies that Lyon is not the capital. Common knowledge and general information about France indicate that the capital is actually Paris, although it is not explicitly mentioned in the given context.\n",
      "\n",
      "[[ ## answer ## ]]\n",
      "Paris\n",
      "\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Capture BASELINE prompt structure\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"1. BASELINE PROMPT (Before Optimization)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "baseline_rag = RAG()\n",
    "test_question = \"What is the capital of France?\"\n",
    "\n",
    "# Run baseline and capture its prompt\n",
    "baseline_output = baseline_rag(test_question)\n",
    "\n",
    "# Get the prompt structure from history\n",
    "print(\"\\nBaseline Prompt Structure:\")\n",
    "print(\"-\" * 70)\n",
    "baseline_history = dspy.inspect_history(n=1)\n",
    "\n",
    "# 2. Capture OPTIMIZED prompt structure  \n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"2. OPTIMIZED PROMPT (After BootstrapFewShot)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Run optimized version\n",
    "optimized_output = compiled_rag(test_question)\n",
    "\n",
    "# Get the optimized prompt structure\n",
    "print(\"\\nOptimized Prompt Structure:\")\n",
    "print(\"-\" * 70)\n",
    "optimized_history = dspy.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5917b3",
   "metadata": {},
   "source": [
    "## Coding: \n",
    "Implement a simple version of EvoPrompt. Represent a prompt as a list of tokens or words. Define two evolutionary operators: mutate (randomly replace or insert a word) and crossover (swap a segment between two prompts). Use an LLM (or a heuristic function) to evaluate fitness (e.g. BLEU score or any task-specific score) of prompts. Start with a few initial prompts and run a few generations of evolution. Did the prompts improve? This could be done on a trivial task (like prompt an LLM to output a specific keyword - evolve prompts to maximize the occurrence of that keyword in the response)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eb32bcea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goal: Evolve prompt to output 'BANANA'\n",
      "\n",
      "Gen 0 | Best Score: 0 | Best Prompt: 'say the word'\n",
      "Gen 1 | Best Score: 0 | Best Prompt: 'say the word'\n",
      "Gen 2 | Best Score: 0 | Best Prompt: 'say the word'\n",
      "Gen 3 | Best Score: 0 | Best Prompt: 'say the word'\n",
      "Gen 4 | Best Score: 0 | Best Prompt: 'say the word'\n",
      "Gen 5 | Best Score: 0 | Best Prompt: 'say the word'\n",
      "Gen 6 | Best Score: 3 | Best Prompt: 'write the BANANA'\n",
      "Gen 7 | Best Score: 3 | Best Prompt: 'write the BANANA'\n",
      "Gen 8 | Best Score: 3 | Best Prompt: 'write the BANANA'\n",
      "Gen 9 | Best Score: 3 | Best Prompt: 'write the BANANA'\n",
      "Gen 10 | Best Score: 3 | Best Prompt: 'write the BANANA'\n",
      "Gen 11 | Best Score: 3 | Best Prompt: 'write the BANANA'\n",
      "Gen 12 | Best Score: 3 | Best Prompt: 'write the BANANA'\n",
      "Gen 13 | Best Score: 3 | Best Prompt: 'write the BANANA'\n",
      "Gen 14 | Best Score: 3 | Best Prompt: 'write the BANANA'\n",
      "Gen 15 | Best Score: 3 | Best Prompt: 'write the BANANA'\n",
      "Gen 16 | Best Score: 3 | Best Prompt: 'write the BANANA'\n",
      "Gen 17 | Best Score: 3 | Best Prompt: 'write the BANANA'\n",
      "Gen 18 | Best Score: 3 | Best Prompt: 'write the BANANA'\n",
      "Gen 19 | Best Score: 3 | Best Prompt: 'write the BANANA'\n",
      "Gen 20 | Best Score: 3 | Best Prompt: 'write the BANANA'\n",
      "Gen 21 | Best Score: 3 | Best Prompt: 'write the BANANA'\n",
      "Gen 22 | Best Score: 3 | Best Prompt: 'write the BANANA'\n",
      "Gen 23 | Best Score: 3 | Best Prompt: 'write the BANANA'\n",
      "Gen 24 | Best Score: 3 | Best Prompt: 'write the BANANA'\n",
      "Gen 25 | Best Score: 3 | Best Prompt: 'write the BANANA'\n",
      "Gen 26 | Best Score: 3 | Best Prompt: 'write the BANANA'\n",
      "Gen 27 | Best Score: 3 | Best Prompt: 'write the BANANA'\n",
      "Gen 28 | Best Score: 3 | Best Prompt: 'write the BANANA'\n",
      "Gen 29 | Best Score: 3 | Best Prompt: 'write the BANANA'\n",
      "Gen 30 | Best Score: 3 | Best Prompt: 'write the BANANA'\n",
      "Gen 31 | Best Score: 3 | Best Prompt: 'write the BANANA'\n",
      "Gen 32 | Best Score: 3 | Best Prompt: 'write the BANANA'\n",
      "Gen 33 | Best Score: 3 | Best Prompt: 'write the BANANA'\n",
      "Gen 34 | Best Score: 3 | Best Prompt: 'write the BANANA'\n",
      "Gen 35 | Best Score: 3 | Best Prompt: 'write the BANANA'\n",
      "Gen 36 | Best Score: 3 | Best Prompt: 'write the BANANA'\n",
      "Gen 37 | Best Score: 3 | Best Prompt: 'write the BANANA'\n",
      "Gen 38 | Best Score: 3 | Best Prompt: 'write the BANANA'\n",
      "Gen 39 | Best Score: 3 | Best Prompt: 'write the BANANA'\n",
      "Gen 40 | Best Score: 3 | Best Prompt: 'write the BANANA'\n",
      "Gen 41 | Best Score: 3 | Best Prompt: 'write the BANANA'\n",
      "Gen 42 | Best Score: 3 | Best Prompt: 'write the BANANA'\n",
      "Gen 43 | Best Score: 3 | Best Prompt: 'write the BANANA'\n",
      "Gen 44 | Best Score: 3 | Best Prompt: 'write the BANANA'\n",
      "Gen 45 | Best Score: 3 | Best Prompt: 'write the BANANA'\n",
      "Gen 46 | Best Score: 3 | Best Prompt: 'write the BANANA'\n",
      "Gen 47 | Best Score: 3 | Best Prompt: 'write the BANANA'\n",
      "Gen 48 | Best Score: 3 | Best Prompt: 'write the BANANA'\n",
      "Gen 49 | Best Score: 3 | Best Prompt: 'write the BANANA'\n",
      "\n",
      "Final Winning Prompt: write the BANANA\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "TARGET_KEYWORD = \"BANANA\"\n",
    "VOCABULARY = [\"say\", \"write\", \"output\", \"the\", \"word\", \"quickly\", \"loudly\", \"BANANA\", \"please\", \"now\"]\n",
    "POPULATION_SIZE = 6\n",
    "GENERATIONS = 50\n",
    "MUTATION_RATE = 0.2\n",
    "\n",
    "# --- CORE FUNCTIONS ---\n",
    "\n",
    "def get_llm_response(prompt_text):\n",
    "    \"\"\"\n",
    "    Simulated LLM: If 'BANANA' is in the prompt, it likely outputs it.\n",
    "    If the prompt is long and clear, the output is better.\n",
    "    \"\"\"\n",
    "    prompt_lower = prompt_text.lower()\n",
    "    if \"banana\" in prompt_lower:\n",
    "        # The better the prompt, the more BANANAs we get\n",
    "        return \" \".join([TARGET_KEYWORD] * (prompt_text.count(\" \") + 1))\n",
    "    return \"I don't know what to say.\"\n",
    "\n",
    "def fitness(prompt_list):\n",
    "    \"\"\"Fitness = Number of target keywords in the output.\"\"\"\n",
    "    prompt_text = \" \".join(prompt_list)\n",
    "    response = get_llm_response(prompt_text)\n",
    "    return response.upper().count(TARGET_KEYWORD)\n",
    "\n",
    "def crossover(parent1, parent2):\n",
    "    \"\"\"Single-point crossover: swap segments of two prompts.\"\"\"\n",
    "    if len(parent1) < 2 or len(parent2) < 2: return parent1, parent2\n",
    "    point = random.randint(1, min(len(parent1), len(parent2)) - 1)\n",
    "    child1 = parent1[:point] + parent2[point:]\n",
    "    child2 = parent2[:point] + parent1[point:]\n",
    "    return child1, child2\n",
    "\n",
    "def mutate(prompt_list):\n",
    "    \"\"\"Randomly replace one word with a word from the vocab.\"\"\"\n",
    "    new_prompt = list(prompt_list)\n",
    "    idx = random.randrange(len(new_prompt))\n",
    "    new_prompt[idx] = random.choice(VOCABULARY)\n",
    "    return new_prompt\n",
    "\n",
    "# --- INITIALIZATION ---\n",
    "# Start with prompts that DON'T have the word BANANA\n",
    "population = [\n",
    "    [\"say\", \"the\", \"word\"],\n",
    "    [\"write\", \"output\", \"now\"],\n",
    "    [\"please\", \"write\", \"quickly\"],\n",
    "    [\"output\", \"the\", \"word\"],\n",
    "    [\"write\", \"the\", \"word\", \"loudly\"],\n",
    "    [\"say\", \"word\", \"please\"]\n",
    "]\n",
    "\n",
    "# --- EVOLUTION LOOP ---\n",
    "print(f\"Goal: Evolve prompt to output '{TARGET_KEYWORD}'\\n\")\n",
    "\n",
    "for gen in range(GENERATIONS):\n",
    "    # 1. Evaluate Fitness\n",
    "    scores = [(p, fitness(p)) for p in population]\n",
    "    # Sort by fitness (descending)\n",
    "    scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    print(f\"Gen {gen} | Best Score: {scores[0][1]} | Best Prompt: '{' '.join(scores[0][0])}'\")\n",
    "    \n",
    "    # 2. Selection: Keep the top 2 as parents\n",
    "    parents = [s[0] for s in scores[:2]]\n",
    "    \n",
    "    # 3. Create next generation\n",
    "    new_population = []\n",
    "    new_population.extend(parents) # Elitism: keep best parents\n",
    "    \n",
    "    while len(new_population) < POPULATION_SIZE:\n",
    "        # Crossover\n",
    "        c1, c2 = crossover(parents[0], parents[1])\n",
    "        \n",
    "        # Mutation\n",
    "        if random.random() < MUTATION_RATE:\n",
    "            c1 = mutate(c1)\n",
    "        if random.random() < MUTATION_RATE:\n",
    "            c2 = mutate(c2)\n",
    "            \n",
    "        new_population.extend([c1, c2])\n",
    "    \n",
    "    population = new_population[:POPULATION_SIZE]\n",
    "\n",
    "print(f\"\\nFinal Winning Prompt: {' '.join(population[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f770e276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Iteration 1 ---\n",
      "\n",
      "--- Iteration 2 ---\n",
      "\n",
      "--- Iteration 3 ---\n",
      "\n",
      "--- Iteration 4 ---\n",
      "\n",
      "--- Iteration 5 ---\n",
      "\n",
      "--- Iteration 6 ---\n",
      "\n",
      "--- Iteration 7 ---\n",
      "\n",
      "--- Iteration 8 ---\n",
      "\n",
      "--- Iteration 9 ---\n",
      "\n",
      "--- Iteration 10 ---\n",
      "\n",
      "--- Iteration 11 ---\n",
      "\n",
      "--- Iteration 12 ---\n",
      "\n",
      "--- Iteration 13 ---\n",
      "\n",
      "--- Iteration 14 ---\n",
      "\n",
      "--- Iteration 15 ---\n",
      "\n",
      "--- Iteration 16 ---\n",
      "\n",
      "--- Iteration 17 ---\n",
      "\n",
      "--- Iteration 18 ---\n",
      "\n",
      "--- Iteration 19 ---\n",
      "\n",
      "--- Iteration 20 ---\n",
      "\n",
      "Final ACE Playbook State:\n",
      "### CURRENT PLAYBOOK\n",
      "\n",
      "[STRATEGIES]\n",
      "- S1: The single most important lesson in this problem is that the drying time of shirts is independent of the number of shirts, given constant environmenta (Helpful: 14, Harmful: 0)\n",
      "\n",
      "[CODE_SNIPPETS]\n",
      "No entries yet.\n",
      "\n",
      "[PITFALLS]\n",
      "- P2: The single most important lesson from this problem is the understanding of time intervals and how to apply them to a real-world scenario. The key stra (Helpful: 0, Harmful: 6)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "from groq import Groq\n",
    "\n",
    "# 1. Setup Groq Client\n",
    "client = Groq(api_key=f\"{GROQ_API_KEY}\")\n",
    "MODEL = \"llama-3.3-70b-versatile\"\n",
    "\n",
    "class Playbook:\n",
    "    def __init__(self):\n",
    "        self.entries = {\n",
    "            \"STRATEGIES\": {},\n",
    "            \"CODE_SNIPPETS\": {},\n",
    "            \"PITFALLS\": {}\n",
    "        }\n",
    "        self.id_counter = 1\n",
    "\n",
    "    def to_text(self):\n",
    "        text = \"### CURRENT PLAYBOOK\\n\"\n",
    "        for section, items in self.entries.items():\n",
    "            text += f\"\\n[{section}]\\n\"\n",
    "            if not items: text += \"No entries yet.\\n\"\n",
    "            for id, data in items.items():\n",
    "                text += f\"- {id}: {data['content']} (Helpful: {data['helpful']}, Harmful: {data['harmful']})\\n\"\n",
    "        return text\n",
    "\n",
    "problems = [\n",
    "    {\"q\": \"If it takes 5 shirts 5 hours to dry outside, how long does it take 30 shirts to dry?\", \"a\": \"5 hours\"},\n",
    "    {\"q\": \"A bat and ball cost $1.10. The bat costs $1.00 more than the ball. How much is the ball?\", \"a\": \"$0.05\"},\n",
    "    {\"q\": \"A doctor gives you 3 pills and tells you to take one every half hour. How long until they are gone?\", \"a\": \"60 minutes\"},\n",
    "    {\"q\": \"In a lake, there is a patch of lily pads. Every day, the patch doubles in size. If it takes 48 days for the patch to cover the entire lake, how long would it take to cover half the lake?\", \"a\": \"47 days\"},\n",
    "    {\"q\": \"If 3 cats can catch 3 bunnies in 3 minutes, how long does it take 100 cats to catch 100 bunnies?\", \"a\": \"3 minutes\"},\n",
    "    {\"q\": \"A man looks at a painting and says, 'Brothers and sisters I have none, but that man's father is my father's son.' Who is in the painting?\", \"a\": \"His son\"},\n",
    "    {\"q\": \"How many birthdays does the average man have?\", \"a\": \"One\"},\n",
    "    {\"q\": \"Some months have 31 days; how many have 28?\", \"a\": \"12\"},\n",
    "    {\"q\": \"If you have 3 apples and you take away 2, how many apples do you have?\", \"a\": \"2\"},\n",
    "    {\"q\": \"A plane crashes on the border of the US and Canada. Where do they bury the survivors?\", \"a\": \"You don't bury survivors\"}\n",
    "] * 3  # Multiplied by 3 to reach 30 iterations for testing reinforcement\n",
    "\n",
    "# 3. ACE Components\n",
    "\n",
    "def generator(problem, playbook):\n",
    "    \"\"\"Solves the problem using the playbook.\"\"\"\n",
    "    prompt = f\"{playbook.to_text()}\\n\\nTask: {problem['q']}\\nSolve the problem. Identify which Playbook IDs helped or misled you.\"\n",
    "    response = client.chat.completions.create(\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        model=MODEL,\n",
    "        temperature=0\n",
    "    ).choices[0].message.content\n",
    "    return response\n",
    "\n",
    "def reflector(problem, response, actual_answer):\n",
    "    \"\"\"Analyzes the success/failure and extracts a lesson.\"\"\"\n",
    "    is_correct = actual_answer.lower() in response.lower()\n",
    "    prompt = f\"Problem: {problem['q']}\\nExpected: {actual_answer}\\nAgent's Solution: {response}\\n\\n\"\n",
    "    prompt += \"Identify the single most important lesson. If wrong, what was the logic error? If right, what was the key strategy?\"\n",
    "    \n",
    "    lesson = client.chat.completions.create(\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        model=MODEL,\n",
    "    ).choices[0].message.content\n",
    "    return lesson, is_correct\n",
    "\n",
    "def curator(lesson, playbook, is_correct):\n",
    "    \"\"\"Merges the lesson into the playbook.\"\"\"\n",
    "    # Logic: Convert lesson to bullet, check for duplicates, update counters\n",
    "    # In a real system, use embeddings. Here, we use a simple keyword check.\n",
    "    category = \"STRATEGIES\" if is_correct else \"PITFALLS\"\n",
    "    \n",
    "    # Check for duplicates (Simple heuristic)\n",
    "    for entry_id, entry in playbook.entries[category].items():\n",
    "        if lesson[:20].lower() in entry['content'].lower():\n",
    "            if is_correct: entry['helpful'] += 1\n",
    "            else: entry['harmful'] += 1\n",
    "            return # Merged\n",
    "\n",
    "    # Add new entry\n",
    "    new_id = f\"{category[0]}{playbook.id_counter}\"\n",
    "    playbook.entries[category][new_id] = {\n",
    "        \"content\": lesson.strip()[:150], # Keep it concise\n",
    "        \"helpful\": 1 if is_correct else 0,\n",
    "        \"harmful\": 0 if is_correct else 1\n",
    "    }\n",
    "    playbook.id_counter += 1\n",
    "\n",
    "# 4. Simulation Execution\n",
    "\n",
    "ace_playbook = Playbook()\n",
    "baseline_context = \"\"\n",
    "ace_scores = []\n",
    "baseline_scores = []\n",
    "\n",
    "for i in range(20):\n",
    "    prob = problems[i]\n",
    "    print(f\"\\n--- Iteration {i+1} ---\")\n",
    "\n",
    "    # Run ACE\n",
    "    gen_output = generator(prob, ace_playbook)\n",
    "    lesson, correct = reflector(prob, gen_output, prob['a'])\n",
    "    curator(lesson, ace_playbook, correct)\n",
    "    ace_scores.append(1 if correct else 0)\n",
    "\n",
    "    # Run Baseline (Just append lessons to a big string)\n",
    "    baseline_context += f\"\\nLesson {i}: {lesson}\"\n",
    "    # (Baseline logic would solve here using baseline_context)\n",
    "\n",
    "print(\"\\nFinal ACE Playbook State:\")\n",
    "print(ace_playbook.to_text())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
